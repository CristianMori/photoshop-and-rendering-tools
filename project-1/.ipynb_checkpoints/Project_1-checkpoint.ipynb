{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Project #1: Hybrid Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS445: Computational Photography - Fall 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Hybrid Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from scipy import signal\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1_file = './index_files/nutmeg.jpg'\n",
    "im2_file = './index_files/DerekPicture.jpg'\n",
    "\n",
    "im1 = cv2.imread(im1_file, cv2.IMREAD_GRAYSCALE)\n",
    "im2 = cv2.imread(im2_file, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ft = np.asarray(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im1)))),dtype=np.uint8)\n",
    "cv2.imshow(\"d\",ft)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_im1 = utils.prompt_eye_selection(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_im2 = utils.prompt_eye_selection(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1, im2= utils.align_images(im1_file, im2_file,pts_im1,pts_im2,save_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to grayscale\n",
    "im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY) / 255.0\n",
    "im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images sanity check\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(im1,cmap='gray')\n",
    "axes[0].set_title('Image 1'), axes[0].set_xticks([]), axes[0].set_yticks([])\n",
    "axes[1].imshow(im2,cmap='gray')\n",
    "axes[1].set_title('Image 2'), axes[1].set_xticks([]), axes[1].set_yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybridImage(im1, im2, cutoff_low, cutoff_high):\n",
    "    '''\n",
    "    Inputs:\n",
    "        im1:    RGB (height x width x 3) or a grayscale (height x width) image\n",
    "                as a numpy array.\n",
    "        im2:    RGB (height x width x 3) or a grayscale (height x width) image\n",
    "                as a numpy array.\n",
    "        cutoff_low: standard deviation for the low-pass filter\n",
    "        cutoff_high: standard deviation for the high-pass filter\n",
    "        \n",
    "    Output:\n",
    "        Return the combination of both images, one filtered with a low-pass filter\n",
    "        and the other with a high-pass filter.\n",
    "    '''    \n",
    "    high_passed = im1 - signal.convolve2d(im1, utils.gaussian_kernel(cutoff_high,3*cutoff_high),boundary='symm', mode='same')\n",
    "    low_passed = signal.convolve2d(im2, utils.gaussian_kernel(cutoff_low,3*cutoff_low),boundary='symm', mode='same')\n",
    "    return high_passed+low_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrary_value = 3  # you should choose meaningful values; you might want to set to a fraction of image size\n",
    "cutoff_low = arbitrary_value\n",
    "cutoff_high = arbitrary_value\n",
    "\n",
    "im_hybrid = hybridImage(im1, im2, cutoff_low, cutoff_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Select top left corner and bottom right corner to crop image\n",
    "# the function returns dictionary of \n",
    "# {\n",
    "#   'cropped_image': np.ndarray of shape H x W\n",
    "#   'crop_bound': np.ndarray of shape 2x2\n",
    "# }\n",
    "cropped_object = utils.interactive_crop(im_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# display the 2D Fourier transform\n",
    "plt.imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(cropped_object[0])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Image Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two out of three types of image enhancement are required.  Choose a good image to showcase each type and implement a method.  This code doesn't rely on the hybrid image part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrast enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('car.jpg', 0)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "\n",
    "equ = cv2.equalizeHist(img)\n",
    "\n",
    "# # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "# clahe = cv2.createCLAHE(clipLimit=2., tileGridSize=(8,8))\n",
    "\n",
    "# lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)  # convert from BGR to LAB color space\n",
    "# l, a, b = cv2.split(lab)  # split on 3 different channels\n",
    "\n",
    "# l2 = clahe.apply(l)  # apply CLAHE to the L-channel\n",
    "\n",
    "# lab = cv2.merge((l2,a,b))  # merge channels\n",
    "# img2 = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)  # convert from LAB to BGR\n",
    "\n",
    "cv2.imshow('Increased contrast', equ)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color enhancement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('me.jpg', 1)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "\n",
    "hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV).astype(np.float32) # convert from BGR to HSV color space\n",
    "(h, s, v) = cv2.split(hsv)\n",
    "\n",
    "hsv = cv2.merge((h,s*1.4,v))  # merge channels\n",
    "img = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)  # convert from HSV to BGR\n",
    "\n",
    "cv2.imshow('Increased saturation', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.real(-np.Inf+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('rickandmorty2.jpg', 1)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "l, a, b = cv2.split(lab)\n",
    "\n",
    "lab = cv2.merge((l,a+50,b))  # merge channels\n",
    "img = cv2.cvtColor(lab.astype(np.uint8), cv2.COLOR_LAB2BGR)  # convert from LAB to BGR\n",
    "\n",
    "cv2.imshow('More red', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('rickandmorty.jpg', 1)\n",
    "cv2.imshow(\"Original image\",img)\n",
    "\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "l, a, b = cv2.split(lab)\n",
    "\n",
    "lab = cv2.merge((l,a,b-30))  # merge channels\n",
    "img = cv2.cvtColor(lab.astype(np.uint8), cv2.COLOR_LAB2BGR)  # convert from LAB to BGR\n",
    "\n",
    "cv2.imshow('less yellow', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
